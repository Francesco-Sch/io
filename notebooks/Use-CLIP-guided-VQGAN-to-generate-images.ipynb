{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "454b8692-e387-4e46-9475-950a1d783b87",
   "metadata": {},
   "source": [
    "# Use CLIP-guided VQGAN to generate images\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque tortor adipiscing duis tortor at cras purus. Quis ultrices at dolor lorem proin maecenas cras senectus. Tortor convallis nec faucibus neque faucibus at ac ut lectus. Morbi cras pharetra lectus elit tempor ornare donec scelerisque purus.\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque tortor adipiscing duis tortor at cras purus. Quis ultrices at dolor lorem proin maecenas cras senectus. Tortor convallis nec faucibus neque faucibus at ac ut lectus. Morbi cras pharetra lectus elit tempor ornare donec scelerisque purus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b36329-b397-41f4-bb47-7be017e1abb2",
   "metadata": {},
   "source": [
    "## 1. Set requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44ab27b1-35df-4830-8769-27d166ecb27c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/home/jovyan/utilities/VQGAN-CLIP'...\n",
      "remote: Enumerating objects: 460, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 460 (delta 2), reused 4 (delta 2), pack-reused 453\u001b[K\n",
      "Receiving objects: 100% (460/460), 32.47 MiB | 12.97 MiB/s, done.\n",
      "Resolving deltas: 100% (247/247), done.\n",
      "/home/jovyan/utilities/VQGAN-CLIP\n",
      "Cloning into 'CLIP'...\n",
      "remote: Enumerating objects: 222, done.\u001b[K\n",
      "remote: Total 222 (delta 0), reused 0 (delta 0), pack-reused 222\u001b[K\n",
      "Receiving objects: 100% (222/222), 8.92 MiB | 8.25 MiB/s, done.\n",
      "Resolving deltas: 100% (111/111), done.\n",
      "Cloning into 'taming-transformers'...\n",
      "remote: Enumerating objects: 1335, done.\u001b[K\n",
      "remote: Total 1335 (delta 0), reused 0 (delta 0), pack-reused 1335\u001b[K\n",
      "Receiving objects: 100% (1335/1335), 409.77 MiB | 7.94 MiB/s, done.\n",
      "Resolving deltas: 100% (280/280), done.\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (1637.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m177.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:01\u001b[0m00:12\u001b[0mm\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl (22.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.1.1)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.28.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2022.5.18.1)\n",
      "Installing collected packages: torch, numpy, torchvision, torchaudio\n",
      "Successfully installed numpy-1.22.4 torch-1.11.0+cu113 torchaudio-0.11.0+cu113 torchvision-0.12.0+cu113\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2022.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (763 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.0/764.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.64.0)\n",
      "Collecting omegaconf\n",
      "  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.6.4-py3-none-any.whl (585 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.5/585.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: IPython in /opt/conda/lib/python3.10/site-packages (8.4.0)\n",
      "Collecting kornia\n",
      "  Downloading kornia-0.6.5-py2.py3-none-any.whl (512 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.8/512.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting imageio\n",
      "  Downloading imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting imageio-ffmpeg\n",
      "  Downloading imageio_ffmpeg-0.4.7-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting einops\n",
      "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
      "Collecting torch_optimizer\n",
      "  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.10/site-packages (from ftfy) (0.2.5)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.10/site-packages (from omegaconf) (5.4.1)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.8.* in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.11.0+cu113)\n",
      "Collecting typing-extensions>=4.0.0\n",
      "  Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (3.20.1)\n",
      "Collecting tensorboard>=2.2.0\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchmetrics>=0.4.1\n",
      "  Downloading torchmetrics-0.9.1-py3-none-any.whl (419 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.7/419.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.22.4)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\n",
      "Collecting pyDeprecate>=0.3.1\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from IPython) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from IPython) (3.0.29)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from IPython) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from IPython) (0.1.3)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from IPython) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from IPython) (0.7.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from IPython) (2.12.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.10/site-packages (from IPython) (62.3.4)\n",
      "Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from IPython) (5.2.2.post1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from IPython) (4.8.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from IPython) (5.1.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio) (9.1.1)\n",
      "Collecting pytorch-ranger>=0.1.1\n",
      "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.28.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->IPython) (0.8.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->IPython) (0.7.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.46.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<=3.20.1\n",
      "  Downloading protobuf-3.19.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.10/site-packages (from stack-data->IPython) (2.0.5)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.10/site-packages (from stack-data->IPython) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->IPython) (0.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.26.9)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.9/157.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (305 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.3/305.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.2.0)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=1137eb2e93705d9c1b462328bfd2e74181df8e6cfc91d339fddbb3d7ff3c7e67\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: tensorboard-plugin-wit, einops, antlr4-python3-runtime, werkzeug, typing-extensions, tensorboard-data-server, regex, pyDeprecate, protobuf, omegaconf, multidict, markdown, imageio-ffmpeg, imageio, grpcio, ftfy, fsspec, frozenlist, async-timeout, yarl, aiosignal, torchmetrics, pytorch-ranger, kornia, google-auth-oauthlib, aiohttp, torch_optimizer, tensorboard, pytorch-lightning\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "elyra-server 3.9.1 requires jupyterlab-git~=0.32, which is not installed.\n",
      "elyra-server 3.9.1 requires typing-extensions<4,>=3.10, but you have typing-extensions 4.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohttp-3.8.1 aiosignal-1.2.0 antlr4-python3-runtime-4.9.3 async-timeout-4.0.2 einops-0.4.1 frozenlist-1.3.0 fsspec-2022.5.0 ftfy-6.1.1 google-auth-oauthlib-0.4.6 grpcio-1.46.3 imageio-2.19.3 imageio-ffmpeg-0.4.7 kornia-0.6.5 markdown-3.3.7 multidict-6.0.2 omegaconf-2.2.2 protobuf-3.19.4 pyDeprecate-0.3.2 pytorch-lightning-1.6.4 pytorch-ranger-0.1.1 regex-2022.6.2 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torch_optimizer-0.3.0 torchmetrics-0.9.1 typing-extensions-4.2.0 werkzeug-2.1.2 yarl-1.7.2\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "100   692  100   692    0     0    318      0  0:00:02  0:00:02 --:--:--   318\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "100  934M  100  934M    0     0  12.9M      0  0:01:11  0:01:11 --:--:-- 13.7M    0  12.8M      0  0:01:12  0:00:09  0:01:03 13.3M10  0:00:19  0:00:51 13.9M0:47  0:00:26 12.5M   0     0  12.8M      0  0:01:12  0:00:55  0:00:17 13.8M  0:00:13 14.3M\n"
     ]
    }
   ],
   "source": [
    "# ------------------\n",
    "# IMPORTS\n",
    "# ------------------\n",
    "import os\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import svelte_widget\n",
    "\n",
    "# ------------------\n",
    "# CREATE DIRECTORY\n",
    "# ------------------\n",
    "if os.path.isdir('/home/jovyan/utilities/VQGAN-CLIP/') is False:\n",
    "    if os.path.isdir('/home/jovyan/utilities/') is False:\n",
    "        os.mkdir('/home/jovyan/utilities/')\n",
    "\n",
    "    os.mkdir('/home/jovyan/utilities/VQGAN-CLIP')\n",
    "\n",
    "# ------------------\n",
    "# CLONE REPOSITORY\n",
    "# ------------------\n",
    "!git clone 'https://github.com/Francesco-Sch/VQGAN-CLIP' /home/jovyan/utilities/VQGAN-CLIP\n",
    "%cd /home/jovyan/utilities/VQGAN-CLIP\n",
    "!git clone 'https://github.com/openai/CLIP'\n",
    "!git clone 'https://github.com/CompVis/taming-transformers'\n",
    "\n",
    "# ------------------\n",
    "# INSTALL PACKAGES\n",
    "# ------------------\n",
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!pip install ftfy regex tqdm omegaconf pytorch-lightning IPython kornia imageio imageio-ffmpeg einops torch_optimizer\n",
    "\n",
    "# ------------------\n",
    "# INSTALL PRE-TRAINED MODELS\n",
    "# ------------------\n",
    "!mkdir checkpoints\n",
    "\n",
    "!curl -L -o checkpoints/vqgan_imagenet_f16_16384.yaml -C - 'https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/files/?p=%2Fconfigs%2Fmodel.yaml&dl=1' #ImageNet 16384\n",
    "!curl -L -o checkpoints/vqgan_imagenet_f16_16384.ckpt -C - 'https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/files/?p=%2Fckpts%2Flast.ckpt&dl=1' #ImageNet 16384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19fd9e5-b7ab-4d95-9a5d-c0fd3de5443c",
   "metadata": {},
   "source": [
    "## 2. Enter text prompt\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque tortor adipiscing duis tortor at cras purus. Quis ultrices at dolor lorem proin maecenas cras senectus. Tortor convallis nec faucibus neque faucibus at ac ut lectus. Morbi cras pharetra lectus elit tempor ornare donec scelerisque purus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf80c3-2f0d-4d20-a106-2e0af98c06ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f039aab-9b6d-4855-adc2-815d252e2464",
   "metadata": {},
   "source": [
    "## 3. Optionally set inital image\n",
    "\n",
    "CAUTION: This is optional and not required to get the model running. If you do not want to use an inital image just leave it empty.\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque tortor adipiscing duis tortor at cras purus. Quis ultrices at dolor lorem proin maecenas cras senectus. Tortor convallis nec faucibus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3b98a-53bf-430b-8042-9d1f7c40f264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dc74b9b-ce80-4e5c-b431-ba210f35c41f",
   "metadata": {},
   "source": [
    "## 4. Set generation options\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque tortor adipiscing duis tortor at cras purus. Quis ultrices at dolor lorem proin maecenas cras senectus. Tortor convallis nec faucibus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb0f2a-e0a2-4097-aa72-d9f21a84a269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c3c71e8-41bd-4798-b624-99e8c8e12ea0",
   "metadata": {},
   "source": [
    "## 5. Validate your settings\n",
    "\n",
    "Click the validation button to check if all your settings and inputs are correct.\n",
    "If everything is correct, you can continue with the generation process under “Start generation”. If something is wrong you’ll get an error message which tells you what is missing and how to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2900ed7b-1979-4d22-8c12-a8027f3f886e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c815fe57-d073-48c0-b1cd-80cac247d497",
   "metadata": {},
   "source": [
    "## 6. Start the generation process\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque tortor adipiscing duis tortor at cras purus. Quis ultrices at dolor lorem proin maecenas cras senectus. Tortor convallis nec faucibus neque faucibus at ac ut lectus. Morbi cras pharetra lectus elit tempor ornare donec scelerisque purus.\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque tortor adipiscing duis tortor at cras purus. Quis ultrices at dolor lorem proin maecenas cras senectus. Tortor convallis nec faucibus neque faucibus at ac ut lectus. Morbi cras pharetra lectus elit tempor ornare donec scelerisque purus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ebc8a9-2014-44c0-9d65-380838801275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/utilities/VQGAN-CLIP\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75dcf49d-98cb-4e87-ae4a-c54202f5f80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Restored from checkpoints/vqgan_imagenet_f16_16384.ckpt\n",
      "Using device: cuda:0\n",
      "Optimising using: Adam\n",
      "Using text prompts: ['Fluorescent plants on a cyberpunk building']\n",
      "Using seed: 16943871009731317440\n",
      "i: 0, loss: 0.976109, losses: 0.976109\n",
      "i: 50, loss: 0.858019, losses: 0.858019\n",
      "i: 100, loss: 0.802089, losses: 0.802089\n",
      "i: 150, loss: 0.805614, losses: 0.805614\n",
      "i: 200, loss: 0.782457, losses: 0.782457\n",
      "i: 250, loss: 0.746023, losses: 0.746023\n",
      "i: 300, loss: 0.688057, losses: 0.688057\n",
      "300it [01:36,  3.12it/s]\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir('/home/jovyan/output/') is False:\n",
    "    os.mkdir('/home/jovyan/output/')\n",
    "\n",
    "if os.path.isdir('/home/jovyan/output/VQGAN-prompt/') is False:\n",
    "    os.mkdir('/home/jovyan/output/VQGAN-prompt/')\n",
    "\n",
    "!python generate.py -p \"Fluorescent plants on a cyberpunk building\" -i 300 -o /home/jovyan/output/VQGAN-prompt/output -s 128 128 -cuts 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4291eaa-7671-4725-aee6-d1754a729271",
   "metadata": {},
   "source": [
    "## 7. Output\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque tortor adipiscing duis tortor at cras purus. Quis ultrices at dolor lorem proin maecenas cras senectus. Tortor convallis nec faucibus neque faucibus at ac ut lectus. Morbi cras pharetra lectus elit tempor ornare donec scelerisque purus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e69325-b30a-4aa2-849f-ec28b487c4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
