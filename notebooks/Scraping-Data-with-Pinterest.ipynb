{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443d4424-ef6b-4a3a-b532-d886421f1e97",
   "metadata": {},
   "source": [
    "# Scraping Data with Pinterest\n",
    "\n",
    "This notebook enables you, to create an image dataset from Pinterest.\n",
    "\n",
    "The creation and curation of datasets is an important part in the work with AI. Datasets enables AI models to learn certain things.Through the creation of a dataset you can therefore determine what the AI model should learn.  \n",
    "Through the creation and curation of an image dataset the designer is able to train an AI model that matches his visual imagination. That is why the creation and curation of image datasets is so important and interesting for designers.  \n",
    "In the end, you could use the created dataset from this notebook to train or fine tune an AI model. More about this under \"7. How to continue\".\n",
    "\n",
    "Pinterest is a very powerful visual search engine, which let you search through millions of images. It also enables user to create collection of images, which are called 'Boards'.  \n",
    "Pinterest uses clever algorithms to find good visual results for a search term. That makes it perfect to create well curated image datasets.  \n",
    "You can find out more about Pinterest through following [this link.](https://about.pinterest.com/)\n",
    "\n",
    "\n",
    "Run the next cell, to initialize the notebook and install all necessary requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d4e56e-ab96-4ce1-9c98-d3710867617b",
   "metadata": {},
   "source": [
    "## 1. Set requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4201a7-1695-49f6-a55e-5909c7c49274",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4==4.9.3 in /opt/conda/lib/python3.10/site-packages (from -r /home/jovyan/utilities/pinterest-crawler/requirements.txt (line 1)) (4.9.3)\n",
      "Requirement already satisfied: bs4==0.0.1 in /opt/conda/lib/python3.10/site-packages (from -r /home/jovyan/utilities/pinterest-crawler/requirements.txt (line 2)) (0.0.1)\n",
      "Requirement already satisfied: certifi==2021.5.30 in /opt/conda/lib/python3.10/site-packages (from -r /home/jovyan/utilities/pinterest-crawler/requirements.txt (line 3)) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer==2.0.4 in /opt/conda/lib/python3.10/site-packages (from -r /home/jovyan/utilities/pinterest-crawler/requirements.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: idna==3.2 in /opt/conda/lib/python3.10/site-packages (from -r /home/jovyan/utilities/pinterest-crawler/requirements.txt (line 5)) (3.2)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /opt/conda/lib/python3.10/site-packages (from -r /home/jovyan/utilities/pinterest-crawler/requirements.txt (line 6)) (5.4.1)\n",
      "Requirement already satisfied: requests==2.26.0 in /opt/conda/lib/python3.10/site-packages (from -r /home/jovyan/utilities/pinterest-crawler/requirements.txt (line 7)) (2.26.0)\n",
      "Requirement already satisfied: selenium==3.141.0 in /opt/conda/lib/python3.10/site-packages (from -r /home/jovyan/utilities/pinterest-crawler/requirements.txt (line 8)) (3.141.0)\n",
      "Requirement already satisfied: soupsieve==2.2.1 in /opt/conda/lib/python3.10/site-packages (from -r /home/jovyan/utilities/pinterest-crawler/requirements.txt (line 9)) (2.2.1)\n",
      "Requirement already satisfied: urllib3==1.26.6 in /opt/conda/lib/python3.10/site-packages (from -r /home/jovyan/utilities/pinterest-crawler/requirements.txt (line 10)) (1.26.6)\n",
      "Requirement already satisfied: wget==3.2 in /opt/conda/lib/python3.10/site-packages (from -r /home/jovyan/utilities/pinterest-crawler/requirements.txt (line 11)) (3.2)\n",
      "Requirement already satisfied: webdriver_manager==3.5.4 in /opt/conda/lib/python3.10/site-packages (from -r /home/jovyan/utilities/pinterest-crawler/requirements.txt (line 12)) (3.5.4)\n",
      "Requirement already satisfied: Pillow==9.1.0 in /opt/conda/lib/python3.10/site-packages (from -r /home/jovyan/utilities/pinterest-crawler/requirements.txt (line 13)) (9.1.0)\n"
     ]
    }
   ],
   "source": [
    "# -----------\n",
    "# IMPORTS\n",
    "# -----------\n",
    "import os\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import svelte_widget\n",
    "\n",
    "# -----------\n",
    "# UTILITIES\n",
    "# -----------\n",
    "if os.path.isdir('/home/jovyan/utilities/pinterest-crawler/') is False:\n",
    "    !git clone https://github.com/Francesco-Sch/Pinterest-crawler-for-jupyter-lab /home/jovyan/utilities/pinterest-crawler\n",
    "\n",
    "if os.path.isdir('/home/jovyan/utilities/pinterest-crawler/') is True:\n",
    "    !pip install -r /home/jovyan/utilities/pinterest-crawler/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e467556-49d1-48c6-9e1f-6dbcdf2d3f96",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Enter your Pinterest login credentials\n",
    "\n",
    "The Pinterest Scraper needs access to Pinterest. For that reason you have to add user credentials so that the scraper can login to Pinterest.\n",
    "Do not worry, the user credentials will only be safed temporarily on that server.\n",
    "\n",
    "Little hint: You could also create a new Pinterest account just for data collection purposes. ;)\n",
    "\n",
    "CAUTION: Works only if 2FA is deactivated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e790ee6-ffa9-46cb-9e19-b54bbf2052d2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db11cc859d9494dbbda3930cbe58d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CrawlerLogin()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CrawlerLogin = svelte_widget.CrawlerLogin()\n",
    "CrawlerLogin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc43ebce-e710-400f-bcf2-147f88ec15dd",
   "metadata": {},
   "source": [
    "## 3. Add Pinterest Links\n",
    "\n",
    "With the following widgets you are able to set all the settings for the scraping process.  \n",
    "First you have to add at least one Pinterest link. You can also add more if you want to scrape different links, to create a bigger image dataset. You can add any Pinterest link you want. The link could be the results of a search you made or a board you collected. \n",
    "Here are two example links, you could use: \n",
    "\n",
    "Link for the search term 'Typography':\n",
    "> https://www.pinterest.de/search/pins/?q=typography&rs=typed&term_meta[]=typography%7Ctyped\n",
    "\n",
    "Link to a Pinterest Board about Editoral Design:\n",
    "> https://www.pinterest.de/loxdelux/cover-editorial-design/\n",
    "\n",
    "After adding your Pinterest links, you can set an output folder for the dataset. You will find the folder in the `datasets` folder. Try to choose a name that represents the scraped dataset in some way.  \n",
    "You can also set the maximum amount of images you want to scrape.\n",
    "\n",
    "After you have set all the settings, you can continute with the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "080e1931-294d-4a64-9b10-6a9f70947f51",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1526bb3dc00e4ffeb73f37d12ae503ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CrawlerLinks()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CrawlerLinks = svelte_widget.CrawlerLinks()\n",
    "CrawlerLinks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9768f5e-a6cb-418d-950d-e670180e6b6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Validate your settings\n",
    "\n",
    "Run the next cell to check if all your settings and inputs are correct.\n",
    "If everything is correct, you can continue with the scraping process under “Start scraping”. If something is wrong you’ll get an error message which tells you what is missing and how to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9fb7c39-e3c2-4da2-bb12-2654d3ca1735",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cac07fe406b42c8af088238c95a0fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation(ValidationMessage='Everthing seems good. Continue with the next cell.', ValidationStatus='success')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Validation = svelte_widget.Validation()\n",
    "\n",
    "try:\n",
    "    CrawlerLogin.CrawlerLoginUserName\n",
    "except NameError:\n",
    "    Validation.ValidationStatus = \"error\"\n",
    "    Validation.ValidationMessage = \"The Username for Pinterest is not set. Execute the cell under '2. Enter your Pinterest login credentials' again.\"\n",
    "\n",
    "    display(Validation)\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    CrawlerLogin.CrawlerLoginPassword\n",
    "except NameError:\n",
    "    Validation.ValidationStatus = \"error\"\n",
    "    Validation.ValidationMessage = \"The Password for Pinterest is not set. Execute the cell under '2. Enter your Pinterest login credentials' again.\"\n",
    "\n",
    "    display(Validation)\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    CrawlerLinks.CrawlerLinks\n",
    "except NameError:\n",
    "    Validation.ValidationStatus = \"error\"\n",
    "    Validation.ValidationMessage = \"There are no links set, which can be scraped. Execute the cell under '3. Add Pinterest Links' again.\"\n",
    "\n",
    "    display(Validation)\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    CrawlerLinks.CrawlerImagesAmount\n",
    "except NameError:\n",
    "    Validation.ValidationStatus = \"error\"\n",
    "    Validation.ValidationMessage = \"There is no amount of images set. Execute the cell under '3. Add Pinterest Links' again.\"\n",
    "\n",
    "    display(Validation)\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    CrawlerLinks.CrawlerOutputFolder\n",
    "except NameError:\n",
    "    Validation.ValidationStatus = \"error\"\n",
    "    Validation.ValidationMessage = \"There is no output folder for the dataset defined. Execute the cell under '3. Add Pinterest Links' again.\"\n",
    "\n",
    "    display(Validation)\n",
    "    raise\n",
    "\n",
    "Validation.ValidationStatus = \"success\"\n",
    "Validation.ValidationMessage = \"Everthing seems good. Continue with the next cell.\"\n",
    "\n",
    "display(Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df853bd-3288-4080-940b-b9fe0cbbdcf3",
   "metadata": {},
   "source": [
    "## 5. Start scraping\n",
    "\n",
    "If the validation passed, you can click the “Start scraping” button to start the scraping process. A progress bar will indicate the progress in the scraping process.\n",
    "\n",
    "While the scraping is running the results will appear in the gallery widget down below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21fdf263-2674-4475-a49b-c3d4c57b5962",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f1df823bdf40ffb7d3a5e3349117b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CrawlerInit()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a4757cc0734e47b864e43a66b16b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CrawlerInit = svelte_widget.CrawlerInit()\n",
    "ScraperOutput = widgets.Output()\n",
    "\n",
    "# Create directory, if it is not existing\n",
    "if os.path.isdir('/home/jovyan/datasets/' + CrawlerLinks.CrawlerOutputFolder) is False:\n",
    "    os.mkdir('/home/jovyan/datasets/' + CrawlerLinks.CrawlerOutputFolder)\n",
    "\n",
    "\n",
    "def scraping(change):\n",
    "    if(change.new is True):\n",
    "        with ScraperOutput:\n",
    "            !python ../utilities/pinterest-crawler/main.py -e '{CrawlerLogin.CrawlerLoginUserName}' -p '{CrawlerLogin.CrawlerLoginPassword}' -d '../datasets/{CrawlerLinks.CrawlerOutputFolder}' -l '{CrawlerLinks.CrawlerLinks[0]}' -g '250' -s '1024' -a '{CrawlerLinks.CrawlerImagesAmount}'\n",
    "\n",
    "\n",
    "CrawlerInit.observe(scraping, names='CrawlerInitClick')\n",
    "\n",
    "display(CrawlerInit, ScraperOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9171a1ba-f6c8-45c4-b183-79f5b9873eb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Explore the collected dataset\n",
    "\n",
    "With the following widget, you get an overview over the image dataset you just scraped.  \n",
    "Through clicking the plus and minus button on the top right corner of the widget, you can zoom in and out the dataset. That way you can have a very close and detailed look on the dataset or get an general overview over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ced301a-b858-497f-b370-e673313c3b55",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6f7b8039d8464e8e8c0c334b9b5d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CrawlerGallery(CrawlerGalleryFolder='datasets/brutalist-interface-design')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CrawlerGallery = svelte_widget.CrawlerGallery()\n",
    "\n",
    "CrawlerGallery.CrawlerGalleryFolder = 'datasets/brutalist-interface-design'\n",
    "CrawlerGallery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e5d632-5c70-431c-b73f-3b6e141c5aed",
   "metadata": {},
   "source": [
    "# 7.  How to continue\n",
    "\n",
    "Well done, you created a dataset via Pinterest! :)  \n",
    "You could use it directly to fine tune StyleGAN3 on your dataset, to create your first own AI model.  \n",
    "You can find out more under this notebook:\n",
    "\n",
    "- [Fine tune StyleGAN3](#)\n",
    "\n",
    "Or if you want to get directly creative with AI you could use VQGAN-CLIP to create new images trough text prompts.  \n",
    "You can find out more under this notebook:\n",
    "\n",
    "- [Use CLIP-guided VQGAN to generate images](#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70356095-1968-4b1d-acb6-3938ba41d1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
